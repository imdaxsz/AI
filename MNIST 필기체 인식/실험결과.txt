1. 은닉 활성화 - sigmoid, 출력 활성화 - softmax, 7.7
optimizer - SGD, loss - mse
은닉층 1개, 뉴런 128개 출력층 1개, 뉴런 10개
초기값 생성 방법 
dropout 사용 X
합성곱 신경망 X
learning rate 값 - 0.1
1. 0.8811
2. 0.8737
3. 0.8799
4. 0.8807
5. 0.8810
mean 0.87928

2. 은닉 활성화 - relu, 출력 활성화 - softmax, 8.4
optimizer - SGD, loss - mse
은닉층 3?개, 뉴런 128?개 출력층 1개, 뉴런 10개
초기값 생성 방법 
dropout 사용 X
합성곱 신경망 O
learning rate 값 - 0.1
1. 0.9626
2. 0.9653
3. 0.9623
4. 0.9655
5. 0.9599
mean - 0.96312

3. 은닉 활성화 - tanh, 출력 활성화 - softmax, 
optimizer - adam, loss - entropy
은닉층 1개, 뉴런 128개 출력층 1개, 뉴런 10개
초기값 생성 방법 
dropout 사용 X
합성곱 신경망 X
learning rate 값 - 0.01
1. 0.9746
2. 0.9739
3. 0.9741
4. 0.976
5. 0.9736
mean 0.97444

4. 은닉 활성화 - relu, 출력 활성화 - softmax, 
optimizer - adam, loss - entropy
은닉층 1개, 뉴런 256개 출력층 1개, 뉴런 10개
초기값 생성 방법 
dropout 사용 X
합성곱 신경망 X
learning rate 값 - 0.01
1. 0.98
2. 0.9802
3. 0.9806
4. 0.9797
5. 0.9796
mean 0.98002

5. 은닉 활성화 - relu, 출력 활성화 - softmax, 
optimizer - adam, loss - entropy
은닉층 3?개, 뉴런 128개 출력층 1개, 뉴런 10개
초기값 생성 방법 
dropout 사용 X
합성곱 신경망 O
learning rate 값 - 0.01

뉴런 256개
1. 0.9892
2. 0.9879
3. 0.9874
4. 0.9854
5. 0.9856
mean 0.9871

32개의 필터 적용 3x3




